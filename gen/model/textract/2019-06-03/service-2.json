{
    "version":"1.0",
    "metadata":{
        "apiVersion":"2019-06-03",
        "endpointPrefix":"textract",
        "jsonVersion":"1.1",
        "protocol":"json",
        "serviceFullName":"Amazon Textract",
        "serviceId":"Textract",
        "signatureVersion":"v4",
        "targetPrefix":"Textract",
        "uid":"textract-2019-06-03"
    },
    "operations":{
	      "DetectDocumentText":{
	          "name":"DetectDocumentText",
            "http":{
                "method":"POST",
                "requestUri":"/"
            },
            "input":{"shape":"DetectDocumentTextRequest"},
            "output":{"shape":"DetectDocumentTextResponse"},
            "errors":[
                {"shape":"AccessDeniedException"},
                {"shape":"BadDocumentException"},
                {"shape":"DocumentTooLargeException"},
                {"shape":"InternalServerError"},
                {"shape":"InvalidParameterException"},
                {"shape":"InvalidS3ObjectException"},
                {"shape":"ProvisionedThroughputExceededException"},
                {"shape":"ThrottlingException"},
                {"shape":"UnsupportedDocumentException"}
            ],
            "documentation":"<p> Detects text in the input document. Amazon Textract can detect lines of text and the words that make up a line of text. The input document must be an image in JPEG or PNG format. DetectDocumentText returns the detected text in an array of Block objects.</p> <p>Each document page has as an associated Block of type PAGE. Each PAGE Block object is the parent of LINE Block objects that represent the lines of detected text on a page. A LINE Block object is a parent for each word that makes up the line. Words are represented by Block objects of type WORD.</p>"
        }},
    "shapes":{
        "AccessDeniedException":{
            "type":"structure",
            "members":{
            },
            "documentation":"<p>You are not authorized to perform the action.</p>",
            "exception":true
        },
        "BadDocumentException":{
            "type":"structure",
            "members":{
            },
            "documentation":"<p>Amazon Textract isn't able to read the document</p>",
            "exception":true
        },
        "DocumentTooLargeException":{
            "type":"structure",
            "members":{
            },
            "documentation":"<p>The document size exceeds the allowed limit. For more information, see <a>limits</a>. </p>",
            "exception":true
        },
        "InternalServerError":{
            "type":"structure",
            "members":{
            },
            "documentation":"<p>Amazon Rekognition experienced a service issue. Try your call again.</p>",
            "exception":true,
            "fault":true
        },
        "InvalidParameterException":{
            "type":"structure",
            "members":{
            },
            "documentation":"<p>Input parameter violated a constraint. Validate your parameter before calling the API operation again.</p>",
            "exception":true
        },
        "InvalidS3ObjectException":{
            "type":"structure",
            "members":{
            },
            "documentation":"<p>Amazon Rekognition is unable to access the S3 object specified in the request.</p>",
            "exception":true
        },
        "ProvisionedThroughputExceededException":{
            "type":"structure",
            "members":{
            },
            "documentation":"<p>The number of requests exceeded your throughput limit. If you want to increase this limit, contact Amazon Rekognition.</p>",
            "exception":true
        },
        "ThrottlingException":{
            "type":"structure",
            "members":{
            },
            "documentation":"<p>Amazon Rekognition is temporarily unable to process the request. Try your call again.</p>",
            "exception":true,
            "fault":true
        },
        "UnsupportedDocumentException":{
            "type":"structure",
            "members":{
            },
            "documentation":"<p>The format of the input document isn't supported. Documents for synchronous operations can be in PNG or JPEG format. Documents for asynchronous operations can also be in PDF format.</p>",
            "exception":true
        },

        "DetectDocumentTextRequest":{
            "type":"structure",
            "required":["Document"],
            "members":{
                "Document":{
                    "shape":"Document",
                    "documentation":"<p>The input document as base64-encoded bytes or an Amazon S3 object. If you use the AWS CLI to call Amazon Rekognition operations, you can't pass image bytes. </p>"
                }
            }
        },
        "Document":{
            "type":"structure",
            "members":{
                "Bytes":{
                    "shape":"DocumentBlob",
                    "documentation":"<p>Blob of image bytes up to 5 MBs.</p>"
                },
                "S3Object":{
                    "shape":"S3Object",
                    "documentation":"<p>Identifies an S3 object as the document source.</p>"
                }
            },
            "documentation":"<p><The input document as base64-encoded bytes or an Amazon S3 object. If you use the AWS CLI to call Amazon Textract operations, you can't pass image bytes. The document must be an image in JPEG or PNG format.</p><p>If you're using an AWS SDK to call Amazon Textract, you might not need to base64-encode image bytes that are passed using the Bytes field.</p>"
        },
        "DocumentBlob":{
            "type":"blob",
            "max":5242880,
            "min":1
        },
        "S3Object":{
            "type":"structure",
            "members":{
                "Bucket":{
                    "shape":"S3Bucket",
                    "documentation":"<p>Name of the S3 bucket.</p>"
                },
                "Name":{
                    "shape":"S3ObjectName",
                    "documentation":"<p>S3 object key name.</p>"
                },
                "Version":{
                    "shape":"S3ObjectVersion",
                    "documentation":"<p>If the bucket is versioning enabled, you can specify the object version. </p>"
                }
            },
            "documentation":"<p>Provides the S3 bucket name and object name.</p> <p>The region for the S3 bucket containing the S3 object must match the region you use for Amazon Rekognition operations.</p> <p>For Amazon Rekognition to process an S3 object, the user must have permission to access the S3 object. For more information, see <a>manage-access-resource-policies</a>. </p>"
        },
        "S3Bucket":{
            "type":"string",
            "max":255,
            "min":3,
            "pattern":"[0-9A-Za-z\\.\\-_]*"
        },
        "S3ObjectName":{
            "type":"string",
            "max":1024,
            "min":1
        },
        "S3ObjectVersion":{
            "type":"string",
            "max":1024,
            "min":1
        },

        "DetectDocumentTextResponse":{
            "type":"structure",
            "members":{
                "Blocks":{
                    "shape":"BlockList",
                    "documentation":"<p>An array of Block objects that contain the text that's detected in the document.</p>"
                },
                "DocumentMetadata":{
                    "shape":"DocumentMetadata",
                    "documentation":"<p> Metadata about the document. It contains the number of pages that are detected in the document.</p>"
                }
            }
        },
        "BlockList":{
            "type":"list",
            "member":{"shape":"Block"}
        },
        "Block":{
            "type":"structure",
            "members":{
                "BlockType":{
                    "shape":"BlockType",
                    "documentation":"<p>The type of text item that's recognized. In operations for text detection, the following types are returned:<ul><li>PAGE - Contains a list of the LINE Block objects that are detected on a document page.</li><li>WORD - A word detected on a document page. A word is one or more ISO basic Latin script characters that aren't separated by spaces.</li><li>LINE - A string of tab-delimited, contiguous words that are detected on a document page.</li></ul></p>"
                },
                "Confidence":{
                    "shape":"Percent",
                    "documentation":"<p>The confidence score that Amazon Textract has in the accuracy of the recognized text and the accuracy of the geometry points around the recognized text.</p>"
                },
                "Geometry":{
                    "shape":"Geometry",
                    "documentation":"<p>The location of the recognized text on the image. It includes an axis-aligned, coarse bounding box that surrounds the text, and a finer-grain polygon for more accurate spatial information.</p>"
                },
                "Id":{
                    "shape":"BlockId",
                    "documentation":"<p>The identifier for the recognized text. The identifier is only unique for a single operation. </p>"
                },
                "Relationships":{
                    "shape":"RelationshipList",
                    "documentation":"<p>A list of child blocks of the current block. For example, a LINE object has child blocks for each WORD block that's part of the line of text. There aren't Relationship objects in the list for relationships that don't exist, such as when the current block has no child blocks. </p>"
                },
                "Text":{
                    "shape":"String",
                    "documentation":"<p>The word or line of text that's recognized by Amazon Textract.</p>"
                }
            }
        },
        "BlockId":{
            "type":"string"
        },
        "BlockType":{
            "type":"string",
            "enum":[
                "LINE",
                "WORD"
            ]
        },
        "Percent":{
            "type":"float",
            "max":100,
            "min":0
        },
        "Geometry":{
            "type":"structure",
            "members":{
                "BoundingBox":{
                    "shape":"BoundingBox",
                    "documentation":"<p>An axis-aligned coarse representation of the detected text's location on the page.</p>"
                },
                "Polygon":{
                    "shape":"Polygon",
                    "documentation":"<p>Within the bounding box, a fine-grained polygon around the detected page.</p>"
                }
            },
            "documentation":"<p>Information about where text detected by is located on a page.</p>"
        },
        "BoundingBox":{
            "type":"structure",
            "members":{
                "Width":{
                    "shape":"Float",
                    "documentation":"<p>Width of the bounding box as a ratio of the overall image width.</p>"
                },
                "Height":{
                    "shape":"Float",
                    "documentation":"<p>Height of the bounding box as a ratio of the overall image height.</p>"
                },
                "Left":{
                    "shape":"Float",
                    "documentation":"<p>Left coordinate of the bounding box as a ratio of overall image width.</p>"
                },
                "Top":{
                    "shape":"Float",
                    "documentation":"<p>Top coordinate of the bounding box as a ratio of overall image height.</p>"
                }
            },
            "documentation":"<p>Identifies the bounding box around the object, face or text. The <code>left</code> (x-coordinate) and <code>top</code> (y-coordinate) are coordinates representing the top and left sides of the bounding box. Note that the upper-left corner of the image is the origin (0,0). </p> <p>The <code>top</code> and <code>left</code> values returned are ratios of the overall image size. For example, if the input image is 700x200 pixels, and the top-left coordinate of the bounding box is 350x50 pixels, the API returns a <code>left</code> value of 0.5 (350/700) and a <code>top</code> value of 0.25 (50/200).</p> <p>The <code>width</code> and <code>height</code> values represent the dimensions of the bounding box as a ratio of the overall image dimension. For example, if the input image is 700x200 pixels, and the bounding box width is 70 pixels, the width returned is 0.1. </p> <note> <p> The bounding box coordinates can have negative values. For example, if Amazon Rekognition is able to detect a face that is at the image edge and is only partially visible, the service can return coordinates that are outside the image bounds and, depending on the image edge, you might get negative values or values greater than 1 for the <code>left</code> or <code>top</code> values. </p> </note>"
        },
        "Float":{"type":"float"},
        "Polygon":{
            "type":"list",
            "member":{"shape":"Point"}
        },
        "Point":{
            "type":"structure",
            "members":{
                "X":{
                    "shape":"Float",
                    "documentation":"<p>The value of the X coordinate for a point on a <code>Polygon</code>.</p>"
                },
                "Y":{
                    "shape":"Float",
                    "documentation":"<p>The value of the Y coordinate for a point on a <code>Polygon</code>.</p>"
                }
            },
            "documentation":"<p>The X and Y coordinates of a point on an image. The X and Y values returned are ratios of the overall image size. For example, if the input image is 700x200 and the operation returns X=0.5 and Y=0.25, then the point is at the (350,50) pixel coordinate on the image.</p> <p>An array of <code>Point</code> objects, <code>Polygon</code>, is returned by . <code>Polygon</code> represents a fine-grained polygon around detected text. For more information, see . </p>"
        },
        "UInteger":{
            "type":"integer",
            "min":0
        },
        "RelationshipList":{
            "type":"list",
            "member":{"shape":"Relationship"}
        },
        "Relationship":{
            "type":"structure",
            "members":{
                "Ids":{
                    "shape":"BlockIdList",
                    "documentation":"<p>An array of IDs for related blocks. You can get the type of the relationship from the Type element.</p>"
                },
                "Type":{
                    "shape":"RelationshipType",
                    "documentation":"<p> The type of relationship that the blocks in the IDs array have with the current block. The relationship can be VALUE or CHILD.</p>"
                }
            }
        },
        "BlockIdList":{
            "type":"list",
            "member":{"shape":"BlockId"}
        },
        "RelationshipType":{
            "type":"string",
            "enum":[
                "VALUE",
                "CHILD"
            ]
        },
        "DocumentMetadata":{
            "type":"structure",
            "members":{
                "Pages":{
                    "shape":"UInteger",
                    "documentation":"<p>The number of pages that are detected in the document.</p>"
                }
            }
        },
        "String":{"type":"string"}
    },
  "documentation":"<p>This is the Amazon Textract API reference.</p>"
}
